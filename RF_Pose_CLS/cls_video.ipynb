{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from WrnchPose import Pose2d\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RF(filename='pose_model.pkl'):\n",
    "    with open(filename, 'rb') as file:\n",
    "        classifier = pickle.load(file)\n",
    "        \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing networks...\n",
      "Initialization done!\n"
     ]
    }
   ],
   "source": [
    "# initialize wrnchAI model\n",
    "wrnchPose = Pose2d(license_key='319074-C0E4EA-494F8E-E93B65-F8A713-AC63B0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joints indexes in wrnchAI\n",
    "jt_def = wrnchPose.joint_definition\n",
    "joints_list = ['NOSE', 'NECK', 'RSHOULDER', 'RELBOW', 'RWRIST',\\\n",
    "               'LSHOULDER', 'LELBOW', 'LWRIST', 'REYE', 'LEYE']\n",
    "joints_wrnch = list(map(jt_def.get_joint_index, joints_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calAngle(x1, y1, x2, y2):\n",
    "    ''' return angle in degrees '''\n",
    "    if y2 < 0 or y1 < 0 or x2 < 0 or x1 < 0:\n",
    "        return 90.\n",
    "    \n",
    "    theta = math.atan2(y2 - y1, x2 - x1) # radian\n",
    "    theta = (theta * 180)/np.pi\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Nose_Neck_A','Rshoulder_Neck_A','Lshoulder_Neck_A','Rshoulder_Relbow_A','Lshoulder_Lelbow_A'\n",
    "# list of indexes for joints between which angle is calculated\n",
    "joints_for_angle = [(0, 1), (2, 1), (5, 1), (2, 3), (5, 6)]\n",
    "joints_for_angle += [(3, 4), (6, 7)]\n",
    "# joints_for_angle = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joints_angles(wrnchPose, frame, joints):\n",
    "    coor = list()\n",
    "    \n",
    "    wrnchPose.estimator.process_frame(frame, wrnchPose.options) # run model\n",
    "    human2d = wrnchPose.estimator.humans_2d() # detected coordinates\n",
    "    \n",
    "    for human in human2d:\n",
    "        points = human.joints()\n",
    "        w,h = frame.shape[1], frame.shape[0]\n",
    "        \n",
    "        for jidx in joints:\n",
    "            coor.append(points[jidx *2]) #x\n",
    "            coor.append(points[jidx *2 + 1]) #y\n",
    "        \n",
    "#         coor.append(w)\n",
    "#         coor.append(h)\n",
    "#         coor.append(posture)\n",
    "        break # for one person only\n",
    "    \n",
    "    return coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting video testing\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # get frmae\n",
    "    ret, frame = cap.read()\n",
    "    # get coordinates \n",
    "    coor = get_joints_angles(wrnchPose, frame, joints_wrnch)\n",
    "    # no prediction when no person\n",
    "    if len(coor) > 10: # no person no points so need enough\n",
    "        # calculate and append angles\n",
    "        for i, j in joints_for_angle:\n",
    "            coor.append( calAngle( coor[2*i], coor[2*i+1], coor[2*j], coor[2*j+1]))\n",
    "        # get prediction\n",
    "        coor = np.asarray(coor) # convert to numpy array\n",
    "        coor = np.expand_dims(coor, axis=0) # expand dimension to fit classifier\n",
    "        pose_res = classifier.predict(coor) # pred pose\n",
    "        # horizontal flip \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # adjust classes because of flip (interchange left and right poses)\n",
    "        pose_res = pose_res[0]\n",
    "        if 'left' in pose_res:\n",
    "            pose_res = pose_res.replace('left', 'right')\n",
    "        elif 'right' in pose_res:\n",
    "            pose_res = pose_res.replace('right', 'left')\n",
    "        # write result on image\n",
    "        frame = cv2.putText(frame, \"Pose: \" + pose_res,\\\n",
    "                            (int(frame.shape[1]*0.15), int(frame.shape[0]*0.15)),\\\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "    # display the image\n",
    "    cv2.imshow(\"FitSit\", frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('fitsit': virtualenv)",
   "language": "python",
   "name": "python36964bitfitsitvirtualenv4e1d2145982b4a409dceb86e0e92a152"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
